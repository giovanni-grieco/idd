Query: {"query":{"multi_match":{"query":"Machine Learning algorithms and applications","fields":["title^2","content"]}}}
{"took":10,"timed_out":false,"_shards":{"total":1,"successful":1,"skipped":0,"failed":0},"hits":{"total":{"value":2664,"relation":"eq"},"max_score":30.405325,"hits":[{"_index":"wikipedia","_type":"_doc","_id":"HCTVSZoBq7KcDrev-4aC","_score":30.405325,"_source":{
  "content": "In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon being observed. Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition, classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition. The concept of \"feature\" is related to that of explanatory variable used in statistical techniques such as linear regression. ==Classification== A set of numeric features can be conveniently described by a feature vector. One of the ways of achieving binary classification is using a linear predictor function (related to the perceptron) with a feature vector as input. The method consists of calculating the scalar product between the feature vector and a vector of weights, comparing the result with a threshold, and deciding the class based on the comparison. Algorithms for classification from a feature vector include nearest neighbor classification, neural networks, and statistical techniques such as Bayesian approaches. ==Examples== In character recognition, features may include histograms counting the number of black pixels along horizontal and vertical directions, number of internal holes, stroke detection and many others. In speech recognition, features for recognizing phonemes can include noise ratios, length of sounds, relative power, filter matches and many others. In spam detection algorithms, features may include the presence or absence of certain email headers, the email structure, the language, the frequency of specific terms, the grammatical correctness of the text. In computer vision, there are a large number of possible features, such as edges and objects. ==Extensions== In pattern recognition and machine learning, a feature vector is an n-dimensional vector of numerical features that represent some object. Many algorithms in machine learning require a numerical representation of objects, since such representations facilitate processing and statistical analysis. When representing images, the feature values might correspond to the pixels of an image, while when representing texts the features might be the frequencies of occurrence of textual terms. Feature vectors are equivalent to the vectors of explanatory variables used in statistical procedures such as linear regression. Feature vectors are often combined with weights using a dot product in order to construct a linear predictor function that is used to determine a score for making a prediction. The vector space associated with these vectors is often called the feature space. In order to reduce the dimensionality of the feature space, a number of dimensionality reduction techniques can be employed. Higher-level features can be obtained from already available features and added to the feature vector; for example, for the study of diseases the feature 'Age' is useful and is defined as Age = 'Year of death' minus 'Year of birth' . This process is referred to as feature construction.Liu, H., Motoda H. (1998) Feature Selection for Knowledge Discovery and Data Mining., Kluwer Academic Publishers. Norwell, MA, USA. 1998.Piramuthu, S., Sikora R. T. Iterative feature construction for improving inductive learning algorithms. In Journal of Expert Systems with Applications. Vol. 36 , Iss. 2 (March 2009), pp. 3401-3406, 2009 Feature construction is the application of a set of constructive operators to a set of existing features resulting in construction of new features. Examples of such constructive operators include checking for the equality conditions {=, ≠}, the arithmetic operators {+,−,×, /}, the array operators {max(S), min(S), average(S)} as well as other more sophisticated operators, for example count(S,C)Bloedorn, E., Michalski, R. Data-driven constructive induction: a methodology and its applications. IEEE Intelligent Systems, Special issue on Feature Transformation and Subset Selection, pp. 30-37, March/April, 1998 that counts the number of features in the feature vector S satisfying some condition C or, for example, distances to other recognition classes generalized by some accepting device. Feature construction has long been considered a powerful tool for increasing both accuracy and understanding of structure, particularly in high-dimensional problems.Breiman, L. Friedman, T., Olshen, R., Stone, C. (1984) Classification and regression trees, Wadsworth Applications include studies of disease and emotion recognition from speech.Sidorova, J., Badia T. Syntactic learning for ESEDA.1, tool for enhanced speech emotion detection and analysis. Internet Technology and Secured Transactions Conference 2009 (ICITST-2009), London, November 9–12. IEEE ==Selection and extraction== The initial set of raw features can be redundant and too large to be managed. Therefore, a preliminary step in many applications of machine learning and pattern recognition consists of selecting a subset of features, or constructing a new and reduced set of features to facilitate learning, and to improve generalization and interpretability. Extracting or selecting features is a combination of art and science; developing systems to do so is known as feature engineering. It requires the experimentation of multiple possibilities and the combination of automated techniques with the intuition and knowledge of the domain expert. Automating this process is feature learning, where a machine not only uses features for learning, but learns the features itself. == See also == * Covariate * Dimensionality reduction * Feature engineering * Hashing trick * Statistical classification *Explainable Artificial Intelligence ==References== Category:Data mining Category:Machine learning Category:Pattern recognition ",
  "title": "Feature (machine learning)"
}},{"_index":"wikipedia","_type":"_doc","_id":"MSTXSZoBq7KcDrev2K9n","_score":25.90587,"_source":{
  "content": "Nello Cristianini (born 1968) is a Professor of Artificial Intelligence in the Department of Computer Science at the University of Bristol. ==Education== Cristianini holds a degree in Physics from the University of Trieste, a Master in Computational Intelligence from the University of London and a PhD from the University of Bristol. Previously he has been an associate professor at the University of California, Davis. ==Research== His research contributions encompass the fields of machine learning, artificial intelligence and bioinformatics. Particularly, his work has focused on statistical analysis of learning algorithms, to its application to support vector machines, kernel methods and other algorithms. Cristianini is the co-author of two widely known books in machine learning, An Introduction to Support Vector Machines and Kernel Methods for Pattern Analysis and a book in bioinformatics \"Introduction to Computational Genomics\". Recent research has focused on the big-data analysis of newspapers content, the analysis of social media content, and the ethical implication of data-driven approaches to science and society. Previous research had focused on unified theoretical frameworks for statistical pattern analysis; machine learning and artificial intelligence; machine translation; bioinformatics. As a practitioner of data-driven AI and Machine Learning, Cristianini frequently gives public talks about the need for a deeper ethical understanding of the effects of modern data-science on society. ==Awards and honours== Cristianini is a recipient of the Royal Society Wolfson Research Merit Award and a current holder of a European Research Council Advanced Grant. In June 2014, Nello Cristianini was included in a list of the \"most influential scientists of the decade\" compiled by Thomson Reuters (listing the top one per cent of scientists who are “the world’s leading scientific minds” and whose publications are among the most influential in their fields). In December 2016 he was included in the list of Top100 most influential researchers in Machine Learning by AMiner - . In 2017 Nello Cristianini was the keynote speaker at the Annual STOA Lecture at the European Parliament. ==References== == External links == * Support Vector Machines: Book and Resources * Personal Web Page * Bioinformatics Text Book * Bristol University fab five among world's finest scientists; The Bristol Post | August 08, 2014 * Five Bristol scientists named among “the world’s leading scientific minds”, University of Bristol * AMiner 2016 most influential scholars in Machine Learning Category:1968 births Category:Living people Category:Alumni of the University of London Category:People from the Province of Gorizia Category:Academics of the University of Bristol Category:Alumni of the University of Bristol Category:University of California, Davis faculty Category:Italian scientist stubs Category:Italian computer scientists Category:European Research Council grantees ",
  "title": "Nello Cristianini"
}},{"_index":"wikipedia","_type":"_doc","_id":"byTVSZoBq7KcDrevy4Du","_score":25.846523,"_source":{
  "content": "Dorien Herremans is a Belgian computer music researcher. Herremans is currently an assistant professor in the Singapore University of Technology and Design,Dr. Dorien Herremans, Assistant Professor, SUTD and research scientist (joint appointment) at the Institute of High Performance Computing, A*STAR. She also works as a certified instructor for the NVIDIA Deep Learning Institute and is director of SUTD Game Lab.SUTD Game Lab Before going to SUTD, she was a recipient of the Marie Sklodowska-Curie Postdoctoral Fellowship at the Centre for Digital Music (C4DM) at Queen Mary University of London, where she worked on the project MorpheuS: Hybrid Machine Learning – Optimization techniques To Generate Structured Music Through Morphing And Fusion.EU MorhpeuS Project She received her Ph.D. in Applied Economics on the topic of Computer Generation and Classification of Music through Operations Research Methods. She graduated as a commercial engineer in management information systems at the [University of Antwerp] in 2005. After that, she worked as a Drupal consultant and was an IT lecturer at the Les Roches University in Bluche, Switzerland. She also worked as a mandaatassistent at the University of Antwerp, in the domain of operations management, supply chain management and operations research. Herremans' current work focuses on automatic music generation, data mining for music classification (hit prediction) and other novel applications in the intersections of AI, machine learning/optimization and music. She is a senior member of the IEEE. Herremans' research on dance hit prediction, automatic piano fingering and AI automatic music generation systems (e.g. MorpheuSMusic and artificial intelligence#MorpheuS) has received attention in the popular press, including international magazines such as Motherboard from Vice Magazine, Channel News Asia's Documentary 'Algorithms: Episode 1: Rage Against The Machine, The Examiner, Belgian national TV Reyers Laat and Belgian and French national radio.France Info – Comment predire qu'une chanson sera un tubeRadio een ==Selected publications== * Herremans D., Chuan C.H, Chew E. 2017. A Functional Taxonomy of Music Generation Systems. ACM Computing Surveys * Dorien Herremans D., Martens D., Sörensen K. 2014. Dance Hit Song Prediction. Journal of New Music Research, Special Issue on Music and Machine Learning. 43:3. pp. 291-302 * Herremans, D., \u0026 Sörensen, K. (2013). Composing fifth species counterpoint music with a variable neighborhood search algorithm. Expert systems with applications, 40(16), 6427-6437 * Herremans, D., \u0026 Chew, E. (2017). MorpheuS: generating structured music with constrained patterns and tension. IEEE Transactions on Affective Computing * Chuan, C. H., \u0026 Herremans, D. (2018, April). Modeling temporal tonal relations in polyphonic music through deep networks with a novel image- based representation. In Proc. of the thirty-second AAAI conference on artificial intelligence * Lin, K. W. E., Balamurali, B. T., Koh, E., Lui, S., \u0026 Herremans, D. (2020). Singing voice separation using a deep convolutional neural network trained by ideal binary mask and cross entropy. Neural Computing and Applications, 32(4), 1037-1050 * Chuan, C. H., Agres, K., \u0026 Herremans, D. (2020). From context to concept: exploring semantic relationships in music with word2vec. Neural Computing and Applications, 32(4), 1023-1036 * Sturm, B. L., Ben-Tal, O., Monaghan, Ú., Collins, N., Herremans, D., Chew, E., ... \u0026 Pachet, F. (2019). Machine learning research that matters for music creation: A case study. Journal of New Music Research, 48(1), 36-55 == References == Category:1982 births Category:Living people ",
  "title": "Dorien Herremans"
}},{"_index":"wikipedia","_type":"_doc","_id":"PCTVSZoBq7KcDrevAGdH","_score":22.29244,"_source":{
  "content": "In computer science, an abstract state machine (ASM) is a state machine operating on states that are arbitrary data structures (structure in the sense of mathematical logic, that is a nonempty set together with a number of functions (operations) and relations over the set). The ASM Method is a practical and scientifically well-founded systems engineering method that bridges the gap between the two ends of system development: * the human understanding and formulation of real-world problems (requirements capture by accurate high-level modeling at the level of abstraction determined by the given application domain) * the deployment of their algorithmic solutions by code-executing machines on changing platforms (definition of design decisions, system and implementation details). The method builds upon three basic concepts: * ASM: a precise form of pseudo-code, generalizing Finite State Machines to operate over arbitrary data structures * ground model: a rigorous form of blueprints, serving as authoritative reference model for the design * refinement: a most general scheme for stepwise instantiations of model abstractions to concrete system elements, providing controllable links between the more and more detailed descriptions at the successive stages of system development. In the original conception of ASMs, a single agent executes a program in a sequence of steps, possibly interacting with its environment. This notion was extended to capture distributed computations, in which multiple agents execute their programs concurrently. Since ASMs model algorithms at arbitrary levels of abstraction, they can provide high-level, low-level and mid-level views of a hardware or software design. ASM specifications often consist of a series of ASM models, starting with an abstract ground model and proceeding to greater levels of detail in successive refinements or coarsenings. Due to the algorithmic and mathematical nature of these three concepts, ASM models and their properties of interest can be analyzed using any rigorous form of verification (by reasoning) or validation (by experimentation, testing model executions). ==History== The concept of ASMs is due to Yuri Gurevich, who first proposed it in the mid-1980s as a way of improving on Turing's thesis that every algorithm is simulated by an appropriate Turing machine. He formulated the ASM Thesis: every algorithm, no matter how abstract, is step-for-step emulated by an appropriate ASM. In 2000, Gurevich axiomatized the notion of sequential algorithms, and proved the ASM thesis for them. Roughly stated, the axioms are as follows: states are structures, the state transition involves only a bounded part of the state, and everything is invariant under isomorphisms of structures. (Structures can be viewed as algebras, which explains the original name evolving algebras for ASMs.) The axiomatization and characterization of sequential algorithms have been extended to parallel and interactive algorithms. In the 1990s, by a community effort, the ASM method was developed, using ASMs for the formal specification and analysis (verification and validation) of computer hardware and software. Comprehensive ASM specifications of programming languages (including Prolog, C, and Java) and design languages (UML and SDL) have been developed. A detailed historical account can be found in the AsmBook (Chapter 9) or in this article. A number of software tools for ASM execution and analysis are available. ==Publications== ===Books=== * AsmBook: Egon Börger, Robert Stärk. Abstract State Machines: A Method for High-Level System Design and Analysis * JBook: R.Stärk, J.Schmid, E.Börger. Java and the Java Virtual Machine: Definition, Verification, Validation * Proceedings/Journal Issues (since 2000) ** 2008: Springer LNCS 5238 Abstract State Machines, B and Z ** 2007: J.UCS Special Issue with and http://osys.grm.hia.no/asm07/proceedings Selected Papers from ASM'07 ** 2006: Springer LNCS 5115 Rigorous Methods for Software Construction and Analysis, ASM and B Dagstuhl Seminar ** 2005: Fundamenta Informatica Special Issue with Selected Papers from ASM'05 (electronic proceedings) ** 2004: Springer LNCS 3052 Abstract State Machines 2004 ** 2003: Springer LNCS 2589 Abstract State Machines 2003: Advances in Theory and Practice ** 2003: TCS special Issue with Selected Papers from ASM'03 ** 2002: Dagstuhl Seminar Report Theory and Applications of Abstract State Machines ** 2001: J.UCS 7.11 Special Issue with Selected Papers from ASM'01 ** 2000: Springer LNCS 1912 Abstract State Machines: Theory and Applications * Comparative case studies with ASM contributions ** Steam-Boiler Control: Specification Case Study, Springer LNCS 1165 ** Production Cell: Software Development Case Study, ASM model ** Railcrossing: Formal Methods for Real-Time Computing, ASM model ** Light Control: Requirements Engineering Case Study, Dagstuhl Seminar ** Invoicing: Requirements Capture Case Study ===Behavioral models for industrial standards=== * OMG for BPMN (version 2006): Springer LNCS 5316 * OASIS for BPEL: IJBPMI 1.4 (2006) * ECMA for C#: \"A high-level modular definition of the semantics of C♯\" * ITU-T for SDL-2000: formal semantics of SDL-2000 and Formal Definition of SDL-2000 - Compiling and Running SDL Specifications as ASM Models * IEEE for VHDL93: E.Boerger, U.Glaesser, W.Mueller. Formal Definition of an Abstract VHDL'93 Simulator by EA-Machines. In: Carlos Delgado Kloos and Peter T.~Breuer (Eds.), Formal Semantics for VHDL, pp. 107–139, Kluwer Academic Publishers, 1995 * ISO for Prolog: \"A mathematical definition of full Prolog\" ==Tools== (in historical order since 2000) *ASMETA, the Abstract State Machine Metamodel and its tool set *AsmL * CoreASM, available at CoreASM, an extensible ASM execution engine *AsmGofer *The XASM open source project ==References== * Y. Gurevich, Evolving Algebras 1993: Lipari Guide, E. Börger (ed.), Specification and Validation Methods, Oxford University Press, 1995, 9-36. () * E. Börger and R. Stärk, Abstract State Machines: A Method for High-Level System Design and Analysis, Springer-Verlag, 2003. () * R. Stärk, J. Schmid and E. Börger, Java and the Java Virtual Machine: Definition, Verification, Validation, Springer-Verlag, 2001. () * Y. Gurevich, Sequential Abstract State Machines capture Sequential Algorithms, ACM Transactions on Computational Logic 1(1) (July 2000), 77-111. ==External links== *Abstract State Machines *AsmCenter *The TASM toolset: specification, simulation, and formal verification of real-time systems Category:Models of computation Category:Formal methods ",
  "title": "Abstract state machine"
}},{"_index":"wikipedia","_type":"_doc","_id":"mSTXSZoBq7KcDrev57BD","_score":21.868614,"_source":{
  "content": "In mathematical folklore, the \"no free lunch\" (NFL) theorem (sometimes pluralized) of David Wolpert and William Macready appears in the 1997 \"No Free Lunch Theorems for Optimization\".Wolpert, D.H., Macready, W.G. (1997), \"No Free Lunch Theorems for Optimization\", IEEE Transactions on Evolutionary Computation 1, 67. Wolpert had previously derived no free lunch theorems for machine learning (statistical inference).Wolpert, David (1996), \"The Lack of A Priori Distinctions between Learning Algorithms\", Neural Computation, pp. 1341–1390. In 2005, Wolpert and Macready themselves indicated that the first theorem in their paper \"state[s] that any two optimization algorithms are equivalent when their performance is averaged across all possible problems\".Wolpert, D.H., and Macready, W.G. (2005) \"Coevolutionary free lunches\", IEEE Transactions on Evolutionary Computation, 9(6): 721–735 The \"no free lunch\" (NFL) theorem is an easily stated and easily understood consequence of theorems Wolpert and Macready actually prove. It is weaker than the proven theorems, and thus does not encapsulate them. Various investigators have extended the work of Wolpert and Macready substantively. See No free lunch in search and optimization for treatment of the research area. While some scholars argue that NFL conveys important insight, others argue that NFL is of little relevance to machine learning research.Whitley, Darrell, and Jean Paul Watson. \"Complexity theory and the no free lunch theorem.\" In Search Methodologies, pp. 317–339. Springer, Boston, MA, 2005.Giraud-Carrier, Christophe, and Foster Provost. \"Toward a justification of meta-learning: Is the no free lunch theorem a show-stopper.\" In Proceedings of the ICML-2005 Workshop on Meta-learning, pp. 12–19. 2005. ==Example== Posit a toy universe that exists for exactly two days and on each day contains exactly one object, a square or a triangle. The universe has exactly four possible histories: # (square, triangle): the universe contains a square on day 1, and a triangle on day 2 # (square, square) # (triangle, triangle) # (triangle, square) Any prediction strategy that succeeds for history #2, by predicting a square on day 2 if there is a square on day 1, will fail on history #1, and vice versa. If all histories are equally likely, then any prediction strategy will score the same, with the same accuracy rate of 0.5. ==Original NFL theorems== Wolpert and Macready give two NFL theorems that are closely related to the folkloric theorem. In their paper, they state: The first theorem hypothesizes objective functions that do not change while optimization is in progress, and the second hypothesizes objective functions that may change. where d_m^y denotes the ordered set of size m of the cost values y associated to input values x \\in X, f:X \\rightarrow Y is the function being optimized and P(d_m^y \\mid f, m, a) is the conditional probability of obtaining a given sequence of cost values from algorithm a run m times on function f. The theorem can be equivalently formulated as follows: Here, blind search means that at each step of the algorithm, the element v \\in V is chosen at random with uniform probability distribution from the elements of V that have not been chosen previously. In essence, this says that when all functions f are equally likely, the probability of observing an arbitrary sequence of m values in the course of optimization does not depend upon the algorithm. In the analytic framework of Wolpert and Macready, performance is a function of the sequence of observed values (and not e.g. of wall-clock time), so it follows easily that all algorithms have identically distributed performance when objective functions are drawn uniformly at random, and also that all algorithms have identical mean performance. But identical mean performance of all algorithms does not imply Theorem 1, and thus the folkloric theorem is not equivalent to the original theorem. Theorem 2 establishes a similar, but \"more subtle\", NFL result for time-varying objective functions. ==Motivation== The NFL theorems were explicitly not motivated by the question of what can be inferred (in the case of NFL for machine learning) or found (in the case of NFL for search) when the \"environment is uniform random\". Rather uniform randomness was used as a tool, to compare the number of environments for which algorithm A outperforms algorithm B to the number of environments for which B outperforms A. NFL tells us that (appropriately weighted) there are just as many environments in both of those sets. This is true for many definitions of what precisely an \"environment\" is. In particular, there are just as many prior distributions (appropriately weighted) in which learning algorithm A beats B (on average) as vice versa. This statement about sets of priors is what is most important about NFL, not the fact that any two algorithms perform equally for the single, specific prior distribution that assigns equal probability to all environments. While the NFL is important to understand the fundamental limitation for a set of problems, it does not state anything about each particular instance of a problem that can arise in practice. That is, the NFL states what is contained in its mathematical statements and it is nothing more than that. For example, it applies to the situations where the algorithm is fixed a priori and a worst-case problem for the fixed algorithm is chosen a posteriori. Therefore, if we have a \"good\" problem in practice or if we can choose a \"good\" learning algorithm for a given particular problem instance, then the NFL does not mention any limitation about this particular problem instance. Though the NFL might seem contradictory to results from other papers suggesting generalization of learning algorithms or search heuristics, it is important to understand the difference between the exact mathematical logic of the NFL and its intuitive interpretation.Kawaguchi, K., Kaelbling, L.P, and Bengio, Y.(2017) \"Generalization in deep learning\", https://arxiv.org/abs/1710.05468 ==Implications for computing and for the scientific method== To illustrate one of the counter-intuitive implications of NFL, suppose we fix two supervised learning algorithms, C and D. We then sample a target function f to produce a set of input-output pairs, d. How should we choose whether to train C or D on d, in order to make predictions for what output would be associated with a point lying outside of d? It is common in almost of all science and statistics to answer this question – to choose between C and D – by running cross-validation on d with those two algorithms. In other words, to decide whether to generalize from d with either C or D, we see which of them has better out-of-sample performance when tested within d. Note that since C and D are fixed, this use of cross-validation to choose between them is itself an algorithm, i.e., a way of generalizing from an arbitrary dataset. Call this algorithm A. (Arguably, A is a simplified model of the scientific method itself.) Note as well though that we could also use anti-cross-validation to make our choice. In other words, we could choose between C and D based on which has worse out-of-sample performance within d. Again, since C and D are fixed, this use of anti-cross-validation is itself an algorithm. Call that algorithm B. NFL tells us (loosely speaking) that B must beat A on just as many target functions (and associated datasets d) as A beats B. In this very specific sense, the scientific method will lose to the \"anti\" scientific method just as readily as it wins.Wolpert, D.H. (2013) \"What the no free lunch theorems really mean\", Ubiquity, Volume 2013, December 2013, However, note that NFL only applies if the target function is chosen from a uniform distribution of all possible functions. If this is not the case, and certain target functions are more likely to be chosen than others, then A may perform better than B overall. The contribution of NFL is that it tells us choosing an appropriate algorithm requires making assumptions about the kinds of target functions the algorithm is being used for. With no assumptions, no \"meta-algorithm\", such as the scientific method, performs better than random choice. While some scholars argue that NFL conveys important insight, others argue that NFL is of little relevance to machine learning research. If Occam's razor is correct, for example if sequences of lower Kolmogorov complexity are more probable than sequences of higher complexity, then (as is observed in real life) some algorithms, such as cross-validation, perform better on average on practical problems (when compared with random choice or with anti- cross-validation).Lattimore, Tor, and Marcus Hutter. \"No free lunch versus Occam’s razor in supervised learning.\" In Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence, pp. 223–235. Springer, Berlin, Heidelberg, 2013. ==See also== * There ain't no such thing as a free lunch ==Notes== ==External links== * No Free Lunch Theorems * Graphics illustrating the theorem Category:Scientific folklore Category:Philosophy of mathematics Category:Mathematical theorems ",
  "title": "No free lunch theorem"
}},{"_index":"wikipedia","_type":"_doc","_id":"ZSTXSZoBq7KcDrev2q8N","_score":20.728153,"_source":{
  "content": "Neural architecture search (NAS) is a technique for automating the design of artificial neural networks (ANN), a widely used model in the field of machine learning. NAS has been used to design networks that are on par or outperform hand-designed architectures. Methods for NAS can be categorized according to the search space, search strategy and performance estimation strategy used: * The search space defines the type(s) of ANN that can be designed and optimized. * The search strategy defines the approach used to explore the search space. * The performance estimation strategy evaluates the performance of a possible ANN from its design (without constructing and training it). NAS is closely related to hyperparameter optimization and is a subfield of automated machine learning (AutoML). ==Reinforcement learning== Reinforcement learning (RL) can underpin a NAS search strategy. Zoph et al. applied NAS with RL targeting the CIFAR-10 dataset and achieved a network architecture that rivals the best manually-designed architecture for accuracy, with an error rate of 3.65, 0.09 percent better and 1.05x faster than a related hand- designed model. On the Penn Treebank dataset, that model composed a recurrent cell that outperforms LSTM, reaching a test set perplexity of 62.4, or 3.6 perplexity better than the prior leading system. On the PTB character language modeling task it achieved bits per character of 1.214. Learning a model architecture directly on a large dataset can be a lengthy process. NASNet addressed this issue by transferring a building block designed for a small dataset to a larger dataset. The design was constrained to use two types of convolutional cells to return feature maps that serve two main functions when convoluting an input feature map: normal cells that return maps of the same extent (height and width) and reduction cells in which the returned feature map height and width is reduced by a factor of two. For the reduction cell, the initial operation applied to the cell’s inputs uses a stride of two (to reduce the height and width). The learned aspect of the design included elements such as which lower layer(s) each higher layer took as input, the transformations applied at that layer and to merge multiple outputs at each layer. In the studied example, the best convolutional layer (or \"cell\") was designed for the CIFAR-10 dataset and then applied to the ImageNet dataset by stacking copies of this cell, each with its own parameters. The approach yielded accuracy of 82.7% top-1 and 96.2% top-5. This exceeded the best human- invented architectures at a cost of 9 billion fewer FLOPS—a reduction of 28%. The system continued to exceed the manually-designed alternative at varying computation levels. The image features learned from image classification can be transferred to other computer vision problems. E.g., for object detection, the learned cells integrated with the Faster-RCNN framework improved performance by 4.0% on the COCO dataset. In the so-called Efficient Neural Architecture Search (ENAS), a controller discovers architectures by learning to search for an optimal subgraph within a large graph. The controller is trained with policy gradient to select a subgraph that maximizes the validation set's expected reward. The model corresponding to the subgraph is trained to minimize a canonical cross entropy loss. Multiple child models share parameters, ENAS requires fewer GPU-hours than other approaches and 1000-fold less than \"standard\" NAS. On CIFAR-10, the ENAS design achieved a test error of 2.89%, comparable to NASNet. On Penn Treebank, the ENAS design reached test perplexity of 55.8. == Evolution == Several groups employed evolutionary algorithms for NAS.Stanley, Kenneth; Miikkulainen, Risto, \"Evolving Neural Networks through Augmenting Topologies\", in: Evolutionary Computation, 2002 Mutations in the context of evolving ANNs are operations such as adding a layer, removing a layer or changing the type of a layer (e.g., from convolution to pooling). On CIFAR-10, evolution and RL performed comparably, while both outperformed random search. ==Hill-climbing== Another group used a hill climbing procedure that applies network morphisms, followed by short cosine-annealing optimization runs. The approach yielded competitive results, requiring resources on the same order of magnitude as training a single network. E.g., on CIFAR-10, the method designed and trained a network with an error rate below 5% in 12 hours on a single GPU. == Multi-objective search == While most approaches solely focus on finding architecture with maximal predictive performance, for most practical applications other objectives are relevant, such as memory consumption, model size or inference time (i.e., the time required to obtain a prediction). Because of that, researchers created a multi-objective search. LEMONADE is an evolutionary algorithm that adopted Lamarckism to efficiently optimize multiple objectives. In every generation, child networks are generated to improve the Pareto frontier with respect to the current population of ANNs. Neural Architect is claimed to be a resource-aware multi-objective RL-based NAS with network embedding and performance prediction. Network embedding encodes an existing network to a trainable embedding vector. Based on the embedding, a controller network generates transformations of the target network. A multi-objective reward function considers network accuracy, computational resource and training time. The reward is predicted by multiple performance simulation networks that are pre-trained or co-trained with the controller network. The controller network is trained via policy gradient. Following a modification, the resulting candidate network is evaluated by both an accuracy network and a training time network. The results are combined by a reward engine that passes its output back to the controller network. == Supernetwork search == RL-based NAS requires thousands of GPU-days of searching/training to achieve state-of- the-art computer vision results as described in the NASNet, mNASNet and MobileNetV3 papers. Supernetwork-based NAS provides a more computationally- efficient solution. The essential idea is to train one supernetwork that spans many options for the final design rather than generating and training thousands of networks independently. In addition to the learned parameters, a set of architecture parameters learn to prefer one module over another. These algorithms are differentiable, allowing the use of gradient descent to optimize them. Supernetwork-based search has been shown to produce competitive results using a fraction of the search-time required by RL-based search methods. For example, FBNet (which is short for Facebook Berkeley Network) demonstrated that supernetwork-based search produces networks that outperform the speed-accuracy tradeoff curve of mNASNet and MobileNetV2 on the ImageNet image-classification dataset. FBNet accomplishes this using over 400x less search time than was used for mNASNet. Further, SqueezeNAS demonstrated that supernetwork-based NAS produces neural networks that outperform the speed- accuracy tradeoff curve of MobileNetV3 on the Cityscapes semantic segmentation dataset, and SqueezeNAS uses over 100x less search time than was used in the MobileNetV3 authors' RL-based search. ==See also== *Neural Network Intelligence ==References== Category:Artificial intelligence ",
  "title": "Neural architecture search"
}},{"_index":"wikipedia","_type":"_doc","_id":"mCTXSZoBq7KcDrev57A2","_score":20.233957,"_source":{
  "content": "The problem is to rapidly find a solution among candidates a, b, and c that is as good as any other, where goodness is either 0 or 1. There are eight instances (\"lunch plates\") fxyz of the problem, where x, y, and z indicate the goodness of a, b, and c, respectively. Procedure (\"restaurant\") A evaluates candidates in the order a, b, c, and B evaluates candidates in reverse that order, but each \"charges\" 1 evaluation in 5 cases, 2 evaluations in 2 cases, and 3 evaluations in 1 case. In computational complexity and optimization the no free lunch theorem is a result that states that for certain types of mathematical problems, the computational cost of finding a solution, averaged over all problems in the class, is the same for any solution method. No solution therefore offers a \"short cut\". This is under the assumption that the search space is a probability density function. It does not apply to the case where the search space has underlying structure (f.e. is a differentiable function) that can be exploited more efficiently (f.e. Newton's method in optimization) than random search or even has closed-form solutions (f.e. the extrema of a quadratic polynomial) that can be determined without search at all. For such probabilistic assumptions, the outputs of all procedures solving a particular type of problem are statistically identical. A colourful way of describing such a circumstance, introduced by David Wolpert and William G. Macready in connection with the problems of search and optimization, is to say that there is no free lunch. Wolpert had previously derived no free lunch theorems for machine learning (statistical inference). Before Wolpert's article was published, Cullen Schaffer independently proved a restricted version of one of Wolpert's theorems and used it to critique the current state of machine learning research on the problem of induction. In the \"no free lunch\" metaphor, each \"restaurant\" (problem-solving procedure) has a \"menu\" associating each \"lunch plate\" (problem) with a \"price\" (the performance of the procedure in solving the problem). The menus of restaurants are identical except in one regard – the prices are shuffled from one restaurant to the next. For an omnivore who is as likely to order each plate as any other, the average cost of lunch does not depend on the choice of restaurant. But a vegan who goes to lunch regularly with a carnivore who seeks economy might pay a high average cost for lunch. To methodically reduce the average cost, one must use advance knowledge of a) what one will order and b) what the order will cost at various restaurants. That is, improvement of performance in problem- solving hinges on using prior information to match procedures to problems. In formal terms, there is no free lunch when the probability distribution on problem instances is such that all problem solvers have identically distributed results. In the case of search, a problem instance is an objective function, and a result is a sequence of values obtained in evaluation of candidate solutions in the domain of the function. For typical interpretations of results, search is an optimization process. There is no free lunch in search if and only if the distribution on objective functions is invariant under permutation of the space of candidate solutions.Streeter, M. (2003) \"Two Broad Classes of Functions for Which a No Free Lunch Result Does Not Hold,\" Genetic and Evolutionary Computation – GECCO 2003, pp. 1418–1430.Igel, C., and Toussaint, M. (2004) \"A No-Free-Lunch Theorem for Non-Uniform Distributions of Target Functions,\" Journal of Mathematical Modelling and Algorithms 3, pp. 313–322.English, T. (2004) No More Lunch: Analysis of Sequential Search, Proceedings of the 2004 IEEE Congress on Evolutionary Computation, pp. 227–234. This condition does not hold precisely in practice, but an \"(almost) no free lunch\" theorem suggests that it holds approximately.S. Droste, T. Jansen, and I. Wegener. 2002. \"Optimization with randomized search heuristics: the (A)NFL theorem, realistic scenarios, and difficult functions,\" Theoretical Computer Science, vol. 287, no. 1, pp. 131–144. ==Overview== Some computational problems are solved by searching for good solutions in a space of candidate solutions. A description of how to repeatedly select candidate solutions for evaluation is called a search algorithm. On a particular problem, different search algorithms may obtain different results, but over all problems, they are indistinguishable. It follows that if an algorithm achieves superior results on some problems, it must pay with inferiority on other problems. In this sense there is no free lunch in search. Alternatively, following Schaffer, search performance is conserved. Usually search is interpreted as optimization, and this leads to the observation that there is no free lunch in optimization. \"The 'no free lunch' theorem of Wolpert and Macready,\" as stated in plain language by Wolpert and Macready themselves, is that \"any two algorithms are equivalent when their performance is averaged across all possible problems.\"Wolpert, D.H., and Macready, W.G. (2005) \"Coevolutionary free lunches,\" IEEE Transactions on Evolutionary Computation, 9(6): 721–735 The \"no free lunch\" results indicate that matching algorithms to problems gives higher average performance than does applying a fixed algorithm to all. Igel and Toussaint and English have established a general condition under which there is no free lunch. While it is physically possible, it does not hold precisely. Droste, Jansen, and Wegener have proved a theorem they interpret as indicating that there is \"(almost) no free lunch\" in practice. To make matters more concrete, consider an optimization practitioner confronted with a problem. Given some knowledge of how the problem arose, the practitioner may be able to exploit the knowledge in selection of an algorithm that will perform well in solving the problem. If the practitioner does not understand how to exploit the knowledge, or simply has no knowledge, then he or she faces the question of whether some algorithm generally outperforms others on real-world problems. The authors of the \"(almost) no free lunch\" theorem say that the answer is essentially no, but admit some reservations as to whether the theorem addresses practice. ==No free lunch (NFL)== A \"problem\" is, more formally, an objective function that associates candidate solutions with goodness values. A search algorithm takes an objective function as input and evaluates candidate solutions one-by-one. The output of the algorithm is the sequence of observed goodness values.A search algorithm also outputs the sequence of candidate solutions evaluated, but that output is unused in this article. Wolpert and Macready stipulate that an algorithm never reevaluates a candidate solution, and that algorithm performance is measured on outputs. For simplicity, we disallow randomness in algorithms. Under these conditions, when a search algorithm is run on every possible input, it generates each possible output exactly once. Because performance is measured on the outputs, the algorithms are indistinguishable in how often they achieve particular levels of performance. Some measures of performance indicate how well search algorithms do at optimization of the objective function. Indeed, there seems to be no interesting application of search algorithms in the class under consideration but to optimization problems. A common performance measure is the least index of the least value in the output sequence. This is the number of evaluations required to minimize the objective function. For some algorithms, the time required to find the minimum is proportional to the number of evaluations. The original no free lunch (NFL) theorems assume that all objective functions are equally likely to be input to search algorithms. It has since been established that there is NFL if and only if, loosely speaking, \"shuffling\" objective functions has no impact on their probabilities. Although this condition for NFL is physically possible, it has been argued that it certainly does not hold precisely. The obvious interpretation of \"not NFL\" is \"free lunch,\" but this is misleading. NFL is a matter of degree, not an all-or-nothing proposition. If the condition for NFL holds approximately, then all algorithms yield approximately the same results over all objective functions. \"Not NFL\" implies only that algorithms are inequivalent overall by some measure of performance. For a performance measure of interest, algorithms may remain equivalent, or nearly so. ===NFL and Kolmogorov randomness=== Almost all elements of the set of all possible functions (in the set-theoretic sense of \"function\") are Kolmogorov random, and hence the NFL theorems apply to a set of functions almost all of which cannot be expressed more compactly than as a lookup table that contains a distinct (and random) entry for each point in the search space. Functions that can be expressed more compactly (for example, by a mathematical expression of reasonable size) are by definition not Kolmogorov random. Further, within the set of all possible objective functions, levels of goodness are equally represented among candidate solutions, hence good solutions are scattered throughout the space of candidates. Accordingly, a search algorithm will rarely evaluate more than a small fraction of the candidates before locating a very good solution. Almost all objective functions are of such high Kolmogorov complexity that they cannot be stored in a particular computer. More precisely, if we model a given physical computer as a register machine with a given size memory on the order of the memories of modern computers, then most objective functions cannot be stored in their memories. There is more information in the typical objective function or algorithm than Seth Lloyd estimates the observable universe is capable of registering. For instance, if each candidate solution is encoded as a sequence of 300 0's and 1's, and the goodness values are 0 and 1, then most objective functions have Kolmogorov complexity of at least 2300 bits, and this is greater than Lloyd's bound of 1090 ≈ 2299 bits. It follows that the original \"no free lunch\" theorem does not apply to what can be stored in a physical computer; instead the so-called \"tightened\" no free lunch theorems need to be applied. It has also been shown that NFL results apply to incomputable functions . ==Formal synopsis of NFL== Y^X is the set of all objective functions f:X→Y, where X is a finite solution space and Y is a finite poset. The set of all permutations of X is J. A random variable F is distributed on Y^X. For all j in J, F o j is a random variable distributed on Y^X, with P(F o j = f) = P(F = f o j−1) for all f in Y^X. Let a(f) denote the output of search algorithm a on input f. If a(F) and b(F) are identically distributed for all search algorithms a and b, then F has an NFL distribution. This condition holds if and only if F and F o j are identically distributed for all j in J. In other words, there is no free lunch for search algorithms if and only if the distribution of objective functions is invariant under permutation of the solution space.The \"only if\" part was first published by Set-theoretic NFL theorems have recently been generalized to arbitrary cardinality X and Y. ==Original NFL theorems== Wolpert and Macready give two principal NFL theorems, the first regarding objective functions that do not change while search is in progress, and the second regarding objective functions that may change. :Theorem 1: For any pair of algorithms a1 and a2 ::\\sum_f P(d_m^y | f, m, a_1) = \\sum_f P(d_m^y | f, m, a_2), where d_m^y denotes the ordered set of size m of the cost values y \\in Y associated to input values x \\in X, f:X \\rightarrow Y is the function being optimized and P(d_m^y | f, m, a) is the conditional probability of obtaining a given sequence of cost values from algorithm a run m times on function f. In essence, this says that when all functions f are equally likely, the probability of observing an arbitrary sequence of m values in the course of search does not depend upon the search algorithm. Theorem 1 establishes a \"more subtle\" NFL result for time-varying objective functions. ==Interpretations of NFL results== A conventional, but not entirely accurate, interpretation of the NFL results is that \"a general-purpose universal optimization strategy is theoretically impossible, and the only way one strategy can outperform another is if it is specialized to the specific problem under consideration\". Several comments are in order: *A general- purpose almost-universal optimizer exists theoretically. Each search algorithm performs well on almost all objective functions. So if one is not concerned with the \"relatively small\" differences between search algorithms, e.g., because computer time is cheap, then you shouldn't worry about no free lunch. *An algorithm may outperform another on a problem when neither is specialized to the problem. Indeed, it may be that both algorithms are among the worst for the problem. More generally, Wolpert and Macready have developed a measure of the degree of \"alignment\" between an algorithm and a distribution over problems (strictly speaking, an inner product). To say that one algorithm matches a distribution better than another is not to say that either has been consciously specialized to the distribution; an algorithm may have good alignment just by luck. *In practice, some algorithms reevaluate candidate solutions. The reason to only consider performance on never-before-evaluated candidates is to make sure that in comparing algorithms one is comparing apples to apples. Moreover, any superiority of an algorithm that never reevaluates candidates over another algorithm that does on a particular problem may have nothing to do with specialization to the problem. *For almost all objective functions, specialization is essentially accidental. Incompressible, or Kolmogorov random, objective functions have no regularity for an algorithm to exploit, as far as the universal Turing machining used to define Kolmogorov randomness is concerned. So presume that there is one, clearly superior choice of universal Turing machine. Then given an objective function that is incompressible for that Turing machine, there is no basis for choosing between two algorithms if both are compressible, as measured using that Turing machine. If a chosen algorithm performs better than most, the result is happenstance. A Kolmogorov random function has no representation smaller than a lookup table that contains a (random) value corresponding to each point in the search space; any function that can be expressed more compactly is, by definition, not Kolmogorov random. In practice, only highly compressible (far from random) objective functions fit in the storage of computers, and it is not the case that each algorithm performs well on almost all compressible functions. There is generally a performance advantage in incorporating prior knowledge of the problem into the algorithm. While the NFL results constitute, in a strict sense, full employment theorems for optimization professionals, it is important to bear the larger context in mind. For one thing, humans often have little prior knowledge to work with. For another, incorporating prior knowledge does not give much of a performance gain on some problems. Finally, human time is very expensive relative to computer time. There are many cases in which a company would choose to optimize a function slowly with an unmodified computer program rather than rapidly with a human-modified program. The NFL results do not indicate that it is futile to take \"pot shots\" at problems with unspecialized algorithms. No one has determined the fraction of practical problems for which an algorithm yields good results rapidly. And there is a practical free lunch, not at all in conflict with theory. Running an implementation of an algorithm on a computer costs very little relative to the cost of human time and the benefit of a good solution. If an algorithm succeeds in finding a satisfactory solution in an acceptable amount of time, a small investment has yielded a big payoff. If the algorithm fails, then little is lost. ==Coevolutionary free lunches== Wolpert and Macready have proved that there are free lunches in coevolutionary optimization.Wolpert, D.H., and Macready, W.G. (2005) \"Coevolutionary free lunches,\" IEEE Transactions on Evolutionary Computation, 9(6): 721–735 Their analysis \"covers 'self-play' problems. In these problems, the set of players work together to produce a champion, who then engages one or more antagonists in a subsequent multiplayer game.\" That is, the objective is to obtain a good player, but without an objective function. The goodness of each player (candidate solution) is assessed by observing how well it plays against others. An algorithm attempts to use players and their quality of play to obtain better players. The player deemed best of all by the algorithm is the champion. Wolpert and Macready have demonstrated that some coevolutionary algorithms are generally superior to other algorithms in quality of champions obtained. Generating a champion through self-play is of interest in evolutionary computation and game theory. The results are inapplicable to coevolution of biological species, which does not yield champions. ==See also== * Evolutionary informatics * Inductive bias * Occam's razor * Simplicity * Ugly duckling theorem == Notes == ==External links== * http://www.no-free-lunch.org *Radcliffe and Surry, 1995, \"Fundamental Limitations on Search Algorithms: Evolutionary Computing in Perspective\" (an early published paper on NFL, appearing soon after Schaffer's ICML paper, which in turn was based on Wolpert's preprint; available in various formats) *NFL publications by Thomas English *NFL publications by Christian Igel and Marc Toussaint *NFL and \"free lunch\" publications by Darrell Whitley *Old list of publications by David Wolpert, William Macready, and Mario Koeppen on optimization and search Category:Mathematical optimization Category:Theorems in computational complexity theory ",
  "title": "No free lunch in search and optimization"
}},{"_index":"wikipedia","_type":"_doc","_id":"VyTXSZoBq7KcDrevsauS","_score":19.819918,"_source":{
  "content": "Mira is a star in the constellation Cetus Mira may also refer to: ==People== * Mira (given name), a given name; includes a list of people with the name * Mira (surname), a surname; includes a list of people with the name * pen name of Mary Leapor (1722–1746), English poet ==Places== * Mira River (Nova Scotia), Canada * Mira Canton, Ecuador * Mira River (Ecuador and Colombia) * Mira, Veneto, a town near Venice, Italy * Mira, Portugal * Mira Municipality, Portugal * Mira River (Portugal) * Mira, Spain * Mira, Illinois, United States * Mira, Louisiana, United States * Kingdom of Mira, part of the kingdom of Arzawa in western Anatolia * Mira, Nadia, a census town in West Bengal, India ==Business== * MIRA Ltd., a UK automotive engineering and development consultancy company * Mira (shopping center), a shopping center in Munich * The Mira Hong Kong, a hotel * Mira Books, a book publishing imprint of Harlequin Enterprises * Macquarie Infrastructure and Real Assets, New York- based subsidiary of privately held Macquarie Holdings (USA) Inc. * Mira Airport, an airport in Serbia ==Science and technology== * IBM Mira, a supercomputer * MIRA procedure, a medical treatment involving tissue grafting and adult stem cells * Margin Infused Relaxed Algorithm, a machine-learning algorithm * Middleware for Robotic Applications, a framework for robotic applications * Monterey Institute for Research in Astronomy, an observatory located in Monterey County, CA * Mira, the codename for Smart Display, a 2002 Microsoft product for a portable touchscreen terminal * Mira (wasp), a wasp genus in the family Encyrtidae ==Vehicles== * Mira (AK-84) or U.S. Army Engineer Port Repair Ship Robert M. Emery * USS Mira (SP-118), a motor launch scheduled for World War I use, but never commissioned * Daihatsu Mira, a compact car model * SS Mira (Finnish ship), a ship that convoyed with the icebreaker Sampo during the Finnish Civil War * SS Mira (German ship), a ship owned by Holm \u0026 Molzen * SS Mira (Italian ship), a ship sunk in May 1943 * SS Mira (Portuguese ship), a ship sunk in November 1916 * SS Mira (Swedish ship), a ship sunk in 1949 * SS Mira (UK ship), a ship that rescued some of the crew from the wreck of the Anna in 1914 ==Music== * Mira (album), a 2014 album by Arild Andersen * Mira (band), an American darkwave band * Mira (world music ensemble), an English world music ensemble * Mira Records, a record label from 1965 to 1968 * PRS Mira, a model of guitar from PRS Guitars ==Film and television== * Mira (film), a 1971 film by Fons Rademakers * Mira (Encantadia), a character in Encantadia * Mira, a character in The Last Legion * Mira Nova, a character from Buzz Lightyear of Star Command ==Video games== * Mira, a playable operator in Tom Clancy's Rainbow Six Siege *Mira (Star Wars), a character in Star Wars: Knights of the Old Republic II: The Sith Lords * Mira, a character from the video game Zero Time Dilemma * Mira, the main setting of Xenoblade Chronicles X * MIRA, A Fictitious company that you work with in Among Us == Other uses == * 3633 Mira, an asteroid * Mira Foundation, a foundation dedicated to assisting people with disabilities * Movement for Islamic Reform in Arabia, a Saudi London-based dissident group * Movimiento Independiente de Renovación Absoluta, a Colombian political party * MIRA (building), a building under construction in San Francisco ==See also== * Meera (disambiguation) * Mira-Bhayandar, a municipality in Maharashtra, India * Mira variable, a type of star named after the supergiant star Mira * Miraa or khat, a plant * Mirah (disambiguation) * Myra (disambiguation) ",
  "title": "Mira (disambiguation)"
}},{"_index":"wikipedia","_type":"_doc","_id":"WiTYSZoBq7KcDrevCLMD","_score":19.748384,"_source":{
  "content": "In computer science, overhead is any combination of excess or indirect computation time, memory, bandwidth, or other resources that are required to perform a specific task. It is a special case of engineering overhead. Overhead can be a deciding factor in software design, with regard to structure, error correction, and feature inclusion. Examples of computing overhead may be found in functional programming, data transfer, and data structures. ==Software design== ===Choice of implementation=== A programmer/software engineer may have a choice of several algorithms, encodings, data types or data structures, each of which have known characteristics. When choosing among them, their respective overhead should also be considered. ===Tradeoffs=== In software engineering, overhead can influence the decision whether or not to include features in new products, or indeed whether to fix bugs. A feature that has a high overhead may not be included – or needs a big financial incentive to do so. Often, even though software providers are well aware of bugs in their products, the payoff of fixing them is not worth the reward, because of the overhead. For example, an implicit data structure or succinct data structure may provide low space overhead, but at the cost of slow performance (space/time tradeoff). ===Run- time complexity of software=== Algorithmic complexity is generally specified using Big O Notation. This makes no comment on how long something takes to run or how much memory it uses, but how its increase depends on the size of the input. Overhead is deliberately not part of this calculation, since it varies from one machine to another, whereas the fundamental running time of an algorithm does not. This should be contrasted with algorithmic efficiency, which takes into account all kinds of resources – a combination (though not a trivial one) of complexity and overhead. ==Examples== ===Computer Programming (run-time and computational overhead)=== Invoking a function introduces a small run-time overhead. Sometimes the compiler can minimize this overhead by inlining some of these function calls. ===CPU Caches=== In a CPU cache, the \"cache size\" (or capacity) refers to how much data a cache stores. For instance, a \"4KB cache\" is a cache that holds 4KB of data. The \"4KB\" in this example excludes overhead bits such as frame, address, and tag information. Presentation for course in Computer Architecture. ===Communications (data transfer overhead)=== Reliably sending a payload of data over a communications network requires sending more than just payload itself. It also involves sending various control and signalling data (TCP) required to reach the destination. This creates a so-called protocol overhead as the additional data does not contribute to the intrinsic meaning of the message.Common Performance Issues in Network Applications Part 1: Interactive Applications, Windows XP Technical Articles, MicrosoftProtocol Overhead in IP/ATM Networks, Minnesota Supercomputer Center In telephony, number dialing and call set-up time are overheads. In 2-way (but half-duplex) radios, the use of \"over\" and other signalling needed to avoid collisions is an overhead. Protocol overhead can be expressed as a percentage of non-application bytes (protocol and frame synchronization) divided by the total number of bytes in the message. ===Encodings and data structures (size overhead)=== The encoding of information and data introduces overhead too. The date and time \"2011-07-12 07:18:47\" can be expressed as Unix time with the 32-bit signed integer `1310447927`, consuming only 4 bytes. Represented as ISO 8601 formatted UTF-8 encoded string `2011-07-12 07:18:47` the date would consume 19 bytes, a size overhead of 375% over the binary integer representation. As XML this date can be written as follows with an overhead of 218 characters, while adding the semantic context that it is a CHANGEDATE with index 1. 2011 07 12 07 18 47 The 349 bytes, resulting from the UTF-8 encoded XML, correlates to a size overhead of 8625% over the original integer representation. ==See also== *Rule of least power *Universal Turing machine ==References== Category:Software engineering ",
  "title": "Overhead (computing)"
}},{"_index":"wikipedia","_type":"_doc","_id":"2iTVSZoBq7KcDrevT28J","_score":19.696604,"_source":{
  "content": "Barbara H. Webb is a Professor of Robotics at the University of Edinburgh. She builds robotic models of insects. == Education == Webb completed a Bachelors in Psychology at the University of Sydney in 1988. She earned her PhD in Artificial Intelligence from the University of Edinburgh in 1993. == Research == Webb joined the University of Nottingham in 1995. In 1999 she moved to the University of Stirling. In 2001 she published the book Biorobotics - Methods and Applications with Thomas Consi. She moved back to the School of Informatics at the University of Edinburgh in May 2003. In 2004 she contributed to the publication Foresight Cognitive Systems Project Research Review, Robotics and Cognition. Webb is interested in understanding how perceptual systems control of behaviour, which she studies by building computational and robotic models. To understand this she studies the behaviour of insects, whose smaller nervous systems are simpler than humans. Her group use computational modelling to understand the behaviour at a neural level. They test their models in agent and robot systems. She believes the behaviours, sensors and small brains of insects should be inspiration for efficient processing algorithms for sensorimotor control. Her group research the navigation of ants, learning abilities of drosophila and movement of crickets. She uses insect inspired robotics as an approach to control system design. She was appointed to a Professor of Biorobotics in 2010. Her inaugural lecture discussed how biological systems are examples of the kind of machines roboticists want to build. That year, she delivered the University of Edinburgh Christmas Lecture. Webb is interested in how ants, with brains small enough to fit on a pin head, can manage to navigate back to their homes. In 2017 she demonstrated how ants use the position of the sun to walk backwards. The discovery attracted media attention and in an interview Webb said that they \"could be taking images and comparing them continuously, but are able to mentally rotate the views to adjust to backward walking\". == References == Category:Living people Category:Roboticists Category:Australian psychologists Category:University of Sydney alumni Category:Academics of Edinburgh Napier University Category:Academics of the University of Nottingham Category:Academics of the University of Stirling Category:Year of birth missing (living people) ",
  "title": "Barbara Webb"
}}]}}
